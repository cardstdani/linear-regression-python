import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

# Data load

data = pd.read_csv('My_Data.csv')
x = data.iloc[:, 0].values
y = data.iloc[:, 1].values

xTrain = np.array(x).reshape(-1, 1)
yTrain = np.array(y).reshape(-1, 1)

# Regression
regression = LinearRegression()
pFeatures = PolynomialFeatures(degree=12)
xPoly = pFeatures.fit_transform(xTrain)
regression.fit(xPoly, yTrain)

# Error calculation
errors = []
averageError = 0

for i in range(len(xTrain)):
    error = regression.predict(xPoly)[i] - yTrain[i]
    errors.append(abs(error))
    plt.plot([xTrain[i], xTrain[i]], [regression.predict(xPoly)[i], regression.predict(xPoly)[i] - error], marker='',
             color='g')
averageError = np.average(errors)
print("Average error: " + str(averageError))

# Plot settings
lines = plt.plot(x, y, marker='o', color='#3F3BFA')
lines += plt.plot(xTrain, regression.predict(xPoly), marker='', color='r')
plt.legend(lines, ["Data line", "Regression line"])
xTest = np.array([5, 8, 10]).reshape(-1, 1)
plt.plot(xTest, regression.predict(pFeatures.fit_transform(xTest)), marker='o', color='y')
plt.grid(color='#1f1f1f', linestyle='dashed', linewidth=0.3)
plt.gca().set_facecolor('#ffffff')
# plt.get_current_fig_manager().full_screen_toggle() #Shows the graph in fullscreen
plt.show()
